[DEFAULT]
data_dir = "/fp/homes01/u01/ec-egilron/wl-coref-ncc/tomls/models01"
train_data = "/fp/homes01/u01/ec-egilron/ncc/wl-ncc_heads/wl-ncc_train_head.jsonl"
dev_data = "/fp/homes01/u01/ec-egilron/ncc/wl-ncc_heads/wl-ncc_development_head.jsonl"
test_data = "/fp/homes01/u01/ec-egilron/ncc/wl-ncc_heads/wl-ncc_test_head.jsonl"
device = "cpu"
bert_model = "bert-large-cased"
bert_window_size = 512
embedding_size = 20
sp_embedding_size = 64
a_scoring_batch_size = 512
hidden_size = 1024
n_hidden_layers = 1
max_span_len = 64
rough_k = 50
bert_finetune = false
dropout_rate = 0.3
bert_learning_rate = 1e-5
learning_rate = 0.0003
train_epochs = 2
bce_loss_weight = 0.5
conll_log_dir = "/fp/homes01/u01/ec-egilron/wl-coref-ncc/tomls/models01/conll_logs"

[models01_000]
bert_model = "/fp/homes01/u01/ec-egilron/norbert2"

[models01_001]
bert_model = "xlm-roberta-base"

[models01_002]
bert_model = "bert-base-multilingual-cased"

[DEFAULT.tokenizer_kwargs.roberta-large]
add_prefix_space = true

[DEFAULT.tokenizer_kwargs.spanbert-large-cased]
do_lower_case = false

[DEFAULT.tokenizer_kwargs.bert-large-cased]
do_lower_case = false
